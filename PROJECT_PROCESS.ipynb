{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJECT_PROCESS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RXbBDXFdO-AE"
      ],
      "authorship_tag": "ABX9TyOpaUDI7ltG7q4CC6cFi/Dd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizbr/RosePrediction/blob/main/PROJECT_PROCESS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxK7RITvOzZF"
      },
      "source": [
        "# NLP Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHkaFFSfO3S2"
      },
      "source": [
        "## Data Acquisition "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2TZoAVjLiZe"
      },
      "source": [
        "\n",
        "Scraped files are SRTs. Then needs to be converted to .txt. \n",
        "\n",
        "Seasons to find: \n",
        "\n",
        "* 24 - Peter Weber \n",
        "* 23 - Colton Underwood \n",
        "* 22 - Arie Luyendyk Jr\n",
        "* 21 - Nick Viall \n",
        "* 20 - Ben Higgins \n",
        "* 19 - Chris Soules "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbBDXFdO-AE"
      },
      "source": [
        "### Hulu \n",
        "[Xonshiz's Hulusubs_dl project on Githib](https://github.com/Xonshiz/Hulusubs_dl) allows me to auth in via user cookies and scrapes the subtitles via command line in terminal. \n",
        "\n",
        "**Closed Captions pulled from HULU:**\n",
        "1.   17 - Sean Lowe\n",
        "2.   18 - Juan Pablo Galavis \n",
        "3.   25 - Matt James (current) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggNXZ-noMehb"
      },
      "source": [
        "#### Converting SRT to TXT files\n",
        "\n",
        "1. Process.py "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "ameunqm7LfMM",
        "outputId": "e32bc9e7-54d8-45cc-be4a-684f1337a67e"
      },
      "source": [
        "## SCRIPT TO RUN ## https://gist.github.com/ndunn219/62263ce1fb59fda08656be7369ce329b#file-srt_to_txt-py\n",
        "# saved as \"process.py\"\n",
        "\n",
        "\"\"\"\n",
        "Creates readable text file from SRT file.\n",
        "\"\"\"\n",
        "import re, sys\n",
        "\n",
        "def is_time_stamp(l):\n",
        "  if l[:2].isnumeric() and l[2] == ':':\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def has_letters(line):\n",
        "  if re.search('[a-zA-Z]', line):\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def has_no_text(line):\n",
        "  l = line.strip()\n",
        "  if not len(l):\n",
        "    return True\n",
        "  if l.isnumeric():\n",
        "    return True\n",
        "  if is_time_stamp(l):\n",
        "    return True\n",
        "  if l[0] == '(' and l[-1] == ')':\n",
        "    return True\n",
        "  if not has_letters(line):\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def is_lowercase_letter_or_comma(letter):\n",
        "  if letter.isalpha() and letter.lower() == letter:\n",
        "    return True\n",
        "  if letter == ',':\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def clean_up(lines):\n",
        "  \"\"\"\n",
        "  Get rid of all non-text lines and\n",
        "  try to combine text broken into multiple lines\n",
        "  \"\"\"\n",
        "  new_lines = []\n",
        "  for line in lines[1:]:\n",
        "    if has_no_text(line):\n",
        "      continue\n",
        "    elif len(new_lines) and is_lowercase_letter_or_comma(line[0]):\n",
        "      #combine with previous line\n",
        "      new_lines[-1] = new_lines[-1].strip() + ' ' + line\n",
        "    else:\n",
        "      #append line\n",
        "      new_lines.append(line)\n",
        "  return new_lines\n",
        "\n",
        "def main(args):\n",
        "  \"\"\"\n",
        "    args[1]: file name\n",
        "    args[2]: encoding. Default: utf-8.\n",
        "      - If you get a lot of [?]s replacing characters,\n",
        "      - you probably need to change file_encoding to 'cp1252'\n",
        "  \"\"\"\n",
        "  file_name = args[1]\n",
        "  file_encoding = 'utf-8' if len(args) < 3 else args[2]\n",
        "  with open(file_name, encoding=file_encoding, errors='replace') as f:\n",
        "    lines = f.readlines()\n",
        "    new_lines = clean_up(lines)\n",
        "  new_file_name = file_name[:-4] + '.txt'\n",
        "  with open(new_file_name, 'w') as f:\n",
        "    for line in new_lines:\n",
        "      f.write(line)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main(sys.argv)\n",
        "\n",
        "\"\"\"\n",
        "NOTES\n",
        " * Run from command line as\n",
        " ** python srt_to_txt.py file_name.srt cp1252\n",
        " * Creates file_name.txt with extracted text from file_name.srt \n",
        "\n",
        " * Script assumes that lines beginning with lowercase letters or commas \n",
        " * are part of the previous line and lines beginning with any other character\n",
        " * are new lines. This won't always be correct. \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f3318619a5a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \"\"\"\n",
            "\u001b[0;32m<ipython-input-1-f3318619a5a0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mfile_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mnew_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9H1dqudM7Op"
      },
      "source": [
        "2. Run process.py via terminal in a batch via python "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rMucGInfMzVh",
        "outputId": "d5e82c48-3cf2-41ee-eafa-1ab9023c9c56"
      },
      "source": [
        "##COMMAND LINE: \n",
        "\"\"\"for file in /Users/elizbr/Documents/NLP/TheBachelor/srt/*; do python3 process.py \"$file\"; done;\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'for file in /Users/elizbr/Documents/NLP/TheBachelor/srt/*; do python3 process.py \"$file\"; done;'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzggVXzkNJYC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ssz75GuPByY"
      },
      "source": [
        "### Youtube? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i4n0wQtPD0U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}